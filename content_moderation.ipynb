{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm5QsmrdBt7n",
        "outputId": "c3835edd-b810-4fe6-8987-f2e28acc400b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory already exists. Skipping download and extraction.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "\n",
        "def download_and_extract_zip(url, target_dir):\n",
        "    # Make a GET request to the URL\n",
        "    response = requests.get(url)\n",
        "    \n",
        "    # Raise an exception for a non-200 status code\n",
        "    response.raise_for_status()\n",
        "    \n",
        "    # Create a BytesIO object from the response content\n",
        "    zip_content = io.BytesIO(response.content)\n",
        "    \n",
        "    # Open the ZIP file\n",
        "    with zipfile.ZipFile(zip_content, 'r') as zip_ref:\n",
        "        # Extract all contents to the target directory\n",
        "        zip_ref.extractall(target_dir)\n",
        "    \n",
        "    print(\"Extraction complete.\")\n",
        "\n",
        "# URL of the ZIP file\n",
        "zip_url = \"https://prod-dcd-datasets-cache-zipfiles.s3.eu-west-1.amazonaws.com/9sxpkmm8xn-1.zip\"\n",
        "\n",
        "# Directory where you want to extract the contents\n",
        "target_directory = \"./data\"\n",
        "\n",
        "# Check if the target directory already contains the extracted files\n",
        "if not os.path.exists(target_directory):\n",
        "    os.makedirs(target_directory)\n",
        "    print(\"Directory created.\")\n",
        "    \n",
        "    # Call the function to download and extract the ZIP file\n",
        "    try:\n",
        "        download_and_extract_zip(zip_url, target_directory)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Failed to download and extract ZIP file: {e}\")\n",
        "else:\n",
        "    print(\"Directory already exists. Skipping download and extraction.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "u-5uNdZOBt7o",
        "outputId": "7d96be09-547b-4ae3-8850-4266dc501ed9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>`- This is not ``creative``.  Those are the di...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>`  :: the term ``standard model`` is itself le...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True or false, the situation as of March 200...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Next, maybe you could work on being less cond...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This page will need disambiguation.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Content  Label\n",
              "0  `- This is not ``creative``.  Those are the di...      0\n",
              "1  `  :: the term ``standard model`` is itself le...      0\n",
              "2    True or false, the situation as of March 200...      0\n",
              "3   Next, maybe you could work on being less cond...      0\n",
              "4               This page will need disambiguation.       0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Path to the CSV file\n",
        "csv_file_path = \"./data/A Curated Hate Speech Dataset/HSData/0_RawData/data_huang_devansh.csv\"\n",
        "\n",
        "# Read the CSV file into a Pandas DataFrame\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame to check if it's loaded correctly\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbhTJ8vDBt7o",
        "outputId": "08797cc6-d775-46f2-9405-23e13a791a04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique Labels:\n",
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "# Print unique values in the \"Label\" column\n",
        "unique_labels = df['Label'].unique()\n",
        "\n",
        "# Display the unique values\n",
        "print(\"Unique Labels:\")\n",
        "print(unique_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrhQFz0oBt7o",
        "outputId": "81bd1732-dbd6-42da-b2f0-8b4460782785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Counts:\n",
            "Label\n",
            "0    708641\n",
            "1    133694\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Count the occurrences of each label\n",
        "label_counts = df['Label'].value_counts()\n",
        "\n",
        "# Display the label counts\n",
        "print(\"Label Counts:\")\n",
        "print(label_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDUaZB83Bt7p"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXa9tpg-Bt7p"
      },
      "source": [
        "1. Remove multiple spaces, hyperlinks, user mentions, emojis, and emoticons converted to text, and removed new line characters\n",
        "2. Removing date and time values\n",
        "3. Removing accented numbers and characters (e.g., ^ea, or ^12)\n",
        "4. The remaining numbers are converted to words\n",
        "5. Removing ampersands from the beginning of words\n",
        "6. Removing the following characters (_\"\\-;%()|+&=*%.,!?:#$@[]/) from the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l_XZwKG1Bt7p",
        "outputId": "002e92ff-c5e6-4f06-d9ab-1c3e4efdd66b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>`- This is not ``creative``. Those are the dic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>` :: the term ``standard model`` is itself les...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True or false, the situation as of March 2002...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Next, maybe you could work on being less cond...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This page will need disambiguation.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Content  Label\n",
              "0  `- This is not ``creative``. Those are the dic...      0\n",
              "1  ` :: the term ``standard model`` is itself les...      0\n",
              "2   True or false, the situation as of March 2002...      0\n",
              "3   Next, maybe you could work on being less cond...      0\n",
              "4               This page will need disambiguation.       0"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Check if the input is a non-null string\n",
        "    if isinstance(text, str) and not pd.isnull(text):\n",
        "        # Remove multiple spaces\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "        # Remove hyperlinks\n",
        "        text = re.sub(r'http\\S+', '', text)\n",
        "\n",
        "        # Remove user mentions (assuming mentions start with @)\n",
        "        text = re.sub(r'@\\w+', '', text)\n",
        "\n",
        "        # Remove emojis and emoticons\n",
        "        emoji_pattern = re.compile(\"[\"\n",
        "                                   u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                                   # Add more ranges as needed\n",
        "                                   \"]+\", flags=re.UNICODE)\n",
        "        text = emoji_pattern.sub(r'', text)\n",
        "\n",
        "        # Remove new line characters\n",
        "        text = text.replace('\\n', '')\n",
        "\n",
        "        return text\n",
        "    else:\n",
        "        # Return an empty string for NaN values\n",
        "        return ''\n",
        "\n",
        "# Create a new DataFrame with preprocessed content\n",
        "df_preprocessed = pd.DataFrame({\n",
        "    'Content': df['Content'].apply(preprocess_text),\n",
        "    'Label': df['Label']\n",
        "})\n",
        "\n",
        "# Display the first few rows of the new DataFrame\n",
        "df_preprocessed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vsRRegJBBt7q",
        "outputId": "1419d37c-b53a-4d27-9a4b-71d2357933ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Content</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is not creative Those are the dictionary...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the term standard model is itself less NPOV ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>True or false the situation as of March 2002 w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Next maybe you could work on being less condes...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This page will need disambiguation</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Content  Label\n",
              "0   This is not creative Those are the dictionary...      0\n",
              "1    the term standard model is itself less NPOV ...      0\n",
              "2  True or false the situation as of March 2002 w...      0\n",
              "3  Next maybe you could work on being less condes...      0\n",
              "4                 This page will need disambiguation      0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from word2number import w2n  # Library for converting numbers to words\n",
        "from unidecode import unidecode  # Library for removing accented characters\n",
        "\n",
        "# Function to remove date and time values\n",
        "def remove_date_time(text):\n",
        "    # Implement your logic to remove date and time values\n",
        "    # For example, you can use regular expressions to identify and remove them\n",
        "    # Here's a simple example that removes strings with digits and colons\n",
        "    return re.sub(r'\\b\\d{1,2}:\\d{2}\\b|\\b\\d{1,2}/\\d{1,2}/\\d{2,4}\\b', '', text)\n",
        "\n",
        "# Function to remove accented numbers and characters\n",
        "def remove_accented_chars(text):\n",
        "    return unidecode(text)\n",
        "\n",
        "# Function to convert remaining numbers to words\n",
        "def convert_numbers_to_words(text):\n",
        "    # Replace numerical values with their word representations\n",
        "    words = []\n",
        "    for word in text.split():\n",
        "        try:\n",
        "            words.append(w2n.word_to_num(word))\n",
        "        except ValueError:\n",
        "            # Handle the case where w2n.word_to_num raises a ValueError\n",
        "            words.append(word)\n",
        "        except IndexError:\n",
        "            # Handle the case where the list is empty\n",
        "            pass\n",
        "    return ' '.join(map(str, words))\n",
        "\n",
        "# Function to remove ampersands from the beginning of words\n",
        "def remove_ampersands(text):\n",
        "    return re.sub(r'\\b&(\\w+)\\b', r'\\1', text)\n",
        "\n",
        "# Function to remove specified characters from the text\n",
        "def remove_special_characters(text):\n",
        "    special_chars = r'_\"\\\\;%\\(\\)|\\+`&=*%,.!?:#$@[\\]/-'\n",
        "    return re.sub('[' + special_chars + ']', '', text)\n",
        "\n",
        "# Apply the defined functions in sequence to the \"Content\" column\n",
        "df_preprocessed['Content'] = df_preprocessed['Content'].apply(remove_date_time)\n",
        "df_preprocessed['Content'] = df_preprocessed['Content'].apply(remove_accented_chars)\n",
        "df_preprocessed['Content'] = df_preprocessed['Content'].apply(convert_numbers_to_words)\n",
        "df_preprocessed['Content'] = df_preprocessed['Content'].apply(remove_ampersands)\n",
        "df_preprocessed['Content'] = df_preprocessed['Content'].apply(remove_special_characters)\n",
        "\n",
        "# Save the new DataFrame to a CSV file\n",
        "df_preprocessed.to_csv('preprocessed_dataset.csv', mode='w', index=False)\n",
        "\n",
        "# Display the first few rows of the new DataFrame\n",
        "df_preprocessed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rRYKsVJ2Bt7q"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming 'df_preprocessed' is your DataFrame with the preprocessed content and labels\n",
        "X = df_preprocessed['Content']\n",
        "y = df_preprocessed['Label']\n",
        "\n",
        "# 60% Train 20% Test 20% Validate\n",
        "# Split the data into training and temporary sets\n",
        "X_train_temp, X_temp, y_train_temp, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
        "X_validate, X_test, y_validate, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc9pVxfJBt7q"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_uR1S39xBt7q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-07 08:09:41.314081: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-07 08:09:41.314108: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-07 08:09:41.314141: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-07 08:09:41.320588: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming X_train_temp, y_train_temp, X_validate, y_validate, X_test, and y_test are available\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train_temp)\n",
        "\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train_temp)\n",
        "X_validate_sequences = tokenizer.texts_to_sequences(X_validate)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 for the padding token\n",
        "\n",
        "max_sequence_length = 100  # Adjust as needed\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length, padding='post')\n",
        "X_validate_padded = pad_sequences(X_validate_sequences, maxlen=max_sequence_length, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oVTbEI5Bt7q",
        "outputId": "e4c5b4c6-26a0-4efa-884b-297130543d26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          37690300  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1280128   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38978749 (148.69 MB)\n",
            "Trainable params: 38978749 (148.69 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-07 08:10:09.073067: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-07 08:10:09.081578: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-07 08:10:09.081834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-07 08:10:09.082936: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-07 08:10:09.083141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-07 08:10:09.083315: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-07 08:10:09.167257: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-07 08:10:09.167546: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-07 08:10:09.167774: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-10-07 08:10:09.167927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6163 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:0d:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense, Dropout\n",
        "\n",
        "# Assuming vocab_size, embedding_dim, max_sequence_length, and num_classes are defined\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(vocab_size, 100, input_length=max_sequence_length))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# Output layer with sigmoid activation for binary classification\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "rgxYv5SRBt7r",
        "outputId": "01d9d2c7-6531-4d32-c201-63c33491fdc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-07 08:10:09.377552: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 202160400 exceeds 10% of free system memory.\n",
            "2023-10-07 08:10:10.052494: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
            "2023-10-07 08:10:10.891512: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2538318970 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2023-10-07 08:10:10.891529: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
            "2023-10-07 08:10:10.894716: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "2023-10-07 08:10:10.905810: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
            "2023-10-07 08:10:10.966070: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15794/15794 [==============================] - 162s 10ms/step - loss: 0.2565 - accuracy: 0.8959 - val_loss: 0.2148 - val_accuracy: 0.9111\n",
            "Epoch 2/10\n",
            "15794/15794 [==============================] - 121s 8ms/step - loss: 0.1608 - accuracy: 0.9374 - val_loss: 0.2085 - val_accuracy: 0.9191\n",
            "Epoch 3/10\n",
            "15794/15794 [==============================] - 120s 8ms/step - loss: 0.1120 - accuracy: 0.9584 - val_loss: 0.2389 - val_accuracy: 0.9185\n",
            "Epoch 4/10\n",
            "15794/15794 [==============================] - 120s 8ms/step - loss: 0.0871 - accuracy: 0.9676 - val_loss: 0.2534 - val_accuracy: 0.9205\n",
            "Epoch 5/10\n",
            "15794/15794 [==============================] - 119s 8ms/step - loss: 0.0727 - accuracy: 0.9726 - val_loss: 0.3193 - val_accuracy: 0.9202\n",
            "Epoch 6/10\n",
            "15794/15794 [==============================] - 119s 8ms/step - loss: 0.0626 - accuracy: 0.9755 - val_loss: 0.3675 - val_accuracy: 0.9186\n",
            "Epoch 7/10\n",
            "15794/15794 [==============================] - 119s 8ms/step - loss: 0.0561 - accuracy: 0.9780 - val_loss: 0.3844 - val_accuracy: 0.9190\n",
            "Epoch 8/10\n",
            "15794/15794 [==============================] - 119s 8ms/step - loss: 0.0522 - accuracy: 0.9792 - val_loss: 0.3756 - val_accuracy: 0.9199\n",
            "Epoch 9/10\n",
            "15794/15794 [==============================] - 119s 8ms/step - loss: 0.0490 - accuracy: 0.9801 - val_loss: 0.4470 - val_accuracy: 0.9198\n",
            "Epoch 10/10\n",
            "15794/15794 [==============================] - 118s 7ms/step - loss: 0.0465 - accuracy: 0.9807 - val_loss: 0.5555 - val_accuracy: 0.9206\n",
            "5265/5265 [==============================] - 6s 1ms/step - loss: 0.5550 - accuracy: 0.9215\n",
            "Test Accuracy: 0.9214980006217957\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train_padded, y_train_temp, epochs=10, batch_size=32, validation_data=(X_validate_padded, y_validate))\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "interpreter": {
      "hash": "b98e62fc36fba69623ae017420bc079ef7773dbe5f00058f9d8193adc20f9093"
    },
    "kernelspec": {
      "display_name": "Python 3.11.5 ('content')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
